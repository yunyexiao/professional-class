# 基于多核的并行编程

@author [ClefZz](https://github.com/ClefZz)

标题后带*是比较重要的

## 概论

* 并发与并行 *

  并发是多个事件在**同一时刻同时发生**。并行是多个任务在**同一时期一起进行**。

  原文：

  >  cocurrency: two of more threads are in progress at the same time
  >
  > parallelism: two or more threads are executing at the same time

  _注释：原文其实并不好理解。关键之处在于并发是同一时刻发生多个事件。并且大部分语境中提及并发时，这些事件之间会发生关系（如竞争和同步）。而并行是多个任务在一段时期里一起执行，任务间可以不发生交互甚至不存在任何关系，强调的只是他们在时间上一起在执行而已。_

  

* 扩展性

  * scale up & scale down
  * 资源拓展性，应用拓展性和技术拓展性

* 加速比 *

  加速比 = 最优串行算法执行时间/并行程序执行时间

  * Amdahl定律：固定问题规模

    `加速比 = 1 / (S + (1 - S) / n)`

    S: 程序中串行部分的比例

    n: 机器规模

  * Gustafson定律：固定时间

    `扩展加速比 = (1 - S) * n + S`

  请注意理解上面两式中S的不同含义。

  例子：

  ​	一程序串行运行时间为t。该程序中，有一部分可以被并行执行。这部分在串行执行时花费4/5t。计算在并行度为4时的加速比。

  ​	Amdahl：1 / (0.2 + 0.8 / 4)  = 2.5

  ​	Gustafson：

  ​		错误算法：0.8 *  4 + 0.2 = 3.4

  ​		正确算法：0.5 * 4 + 0.5 = 2.5

  ​	Gustafson中的S，指的是**并行执行时时间的占比**。所以不是1 : 4，而是1 : (4 / 4) = 1 : 1，所以S = 0.5。



## 模型与系统

### 概述

* Flynn分类法

  SISD：单任务架构的传统计算机

  SIMD：向量机

  MISD：几乎没有现实存在的机器

  MIMD：分shared memory类（如现代多核处理计算机）和distributed memory类（如集群）

* 存储层次结构

### 并行计算机模型

* 操作与开销

  * 操作：
    * 计算操作
    * 并行操作
    * 交互操作
  * 开销
    * 并行开销
    * 通信开销
    * 同步开销
    * 负载不均衡开销

  注意辨识各种开销，回忆上课的例子

  _要点就是上面三种开销是它们操作**本身**的开销。而随后带来的影响比如线程等待啊挂起啊都是负载不均衡开销。_

  _比如去获取一个互斥量，这个函数调用和它做的一些操作，这些是同步开销。而如果这个mutext现在被其他线程拿着，导致现在这个线程被操作系统挂起，等到mutex解锁了再继续执行，这段停止执行的时间是负载不均衡开销。_

* PRAM模型 *

  PRAM(n)：

  ​	n个处理器，1个共享存储空间，1个公共时钟。

  ​	所有处理器按照统一的时间步执行，称为一个周期。一个周期只能执行一条指令，可以是空指令。

  ​	周期更替时，所有处理器蕴式同步，同步开销为零。通过共享变量同步，通信开销忽略不计。并行开销也忽略不计。所有唯一计及的开销是负载不均衡开销。

  特点：

  * MIMD
  * 细粒度
  * 严格同步（指令级同步）
  * 零开销
  * 单一地址空间，均匀存储器访问，共享变量

  计算：

  ​	自己看例子。一定要弄懂。

* APRAM

  取消PRAM中的全局时钟。每个处理器有自己的时钟。

  由路障进行同步。

  指令完成时间是有限但非确定的。

* BSP

  以超步（一组计算、通信、路障操作）进行同步。

  特点：

  * 可变颗粒度
  * 松同步
  * 非零开销
  * 消息传递或共享变量

### 内存访问模型

* 多级存储结构

* UMA *

  * 物理存储器被所以节点共享
  * 所有节点访问任意存储单元的时间相同
  * 发生访存竞争时，仲裁策略平等对待每个节点，即每个节点机会均等
  * 各节点的CPU可带有局部私有高速缓存
  * 外围I/O设备也可以共享，且每个节点有平等的访问权利

* NUMA *

  * 物理存储器被所以节点共享，任意节点可以直接访问任意内存模块
  * 节点访问内存模块的速度不同，访问本地模块的速度一般是访问其他节点内存模块的三倍以上
  * 发生访存竞争时，仲裁策略可能是不等价的
  * 各节点的CPU可带有局部私有高速缓存
  * 外围I/O也可以共享，但对各节点的不等价的

* 请注意UMA和NUMA都是在所有CPU共享相同地址空间的前提下

* NORMA

  * 所有储存器私有
  * （大多数情况下）不支持直接访问远程存储器
  * 在DSM中，NORMA就消失了（_请注意这句话，并不是说NORMA和DSM是互斥的，DSM可以建立在NORMA之上，作为封装和高层抽象。但是它们不能在同一架构层次中同时存在_)

* CCNUMA和COMA

  ​	两者都和缓存有关。COMA将所有存储器视为缓存，在使用某一份数据时，将其**迁移**到本地区域。CCNUMA则是在使用时，将其**拷贝**至本地区域。

  ​	即，COMA中同一份数据在全部存储区域中有且仅有一份，处理单元间通信主要用于获取和迁移数据。CCNUMA同一份数据在全部存储区域中会有多分，处理单元间通信主要用于维持缓存一致性。

  ​	CCNUMA和多核CPU中的cache、缓存一致性协议有很大的相似性。

* 缓存一致性策略

  写直达法 & 写回法

* 监听一致性协议

  * 写无效协议

    本地高速缓存被修改后，使得所有其他位置的数据拷贝失效

  * 写更新协议

    本地高速缓存被修改后，通过广播修改后的数据，使得所有其他位置的数据拷贝被更新为最新

* 总结：内存访问模型的分类

  ```
                       / UMA
         / 单地址空间  |         / COMA
        |              \ NUMA  |  CC-NUMA
  MIMD  |                      \ NCC-NUMA
        |                    / Cluster  \
         \ 多地址空间(NORMA) |            这俩是下一节的，不是访存模型的一种
                             \ MPP      /
  ```

  

  ### 典型并行计算系统

  * SMP *
    * 结构对称，采用单一操作系统
    * 所有处理器通过高速总线或交叉开关与共享存储器相连，具有单一的地址空间
    * 通过共享变量通信，快捷且编程容易
    * 存储器和I/O负载大，容易成为系统的瓶颈，限制了系统中处理器的数量
    * 容错性极低（单点失效就会导致整个系统崩溃）
    * 拓展性差
  * PVP
  * MPP
    * 专门设计制造的高速互联网络
    * 节点内有一个或多个处理器，高速缓存、本地存储器和互联网络
    * 每个处理器能直接访问的只有本地存储器，不能访问其他处理器的存储器
    * 程序由多个进程组成，每个都有其私有空间。进程间采用消息传递
    * 使用专用硬件提升性能，技术复杂，成本高。
    * 紧耦合
  * Cluster（COW）
    * 每个节点都是完整的计算机，运行完整的操作系统
    * 通过低成本的商用网络互连
    * 松耦合
    * 高性价比
    * 良好的可拓展性
    * 易获得性，配置灵活
    * 提供多用途的并行计算系统



## 并行编程基础

* 显式并行和隐式并行

* 并行化方法

  * 库例程

    易于实现，不需要新编译器；没有编译期检查、分析和优化

  * 新构造

    允许编译期检查、分析和优化；实现困难，需要新编译器

  * 命令

    介于上两者之间，在串行平台上无效

* 并行编程模型

  * 共享存储器模型
  * 消息传递模型
  * 数据并行模型

|              | 数据并行      | 消息传递           | 共享变量     |
| ------------ | ------------- | ------------------ | ------------ |
| 控制流       | 单            | 多                 | 多           |
| 同步         | 松散同步      | 异步               | 异步         |
| 地址空间     | 单            | 多                 | 单           |
| 交互         | 隐式          | 显式               | 显式         |
| 数据分配     | 隐式或半显式  | 显式               | 隐式或半隐式 |
| 典型代表     | HPF，IPP      | MPI，PVM           | OpenMP       |
| 可移植性     | SMP，DSM，MPP | 所有主流并行计算机 | SMP，DSM     |
| 并行粒度     | 进程级细粒度  | 进程级大粒度       | 线程级细粒度 |
| 数据储存方式 | 共享存储      | 共享存储           | 分布式存储   |
| 难度         | 较容易        | 较难               | 容易         |

_这里死记比较难，有相应的经验会好理解很多。数据并行可以参考Matlab这种基于向量的编程结构。共享变量就是常规的方式。消息传递可以参考Erlang的进程通信方式（Erlang进程内部还是用的共享变量方式的）（再顺便一提，这门课的教学计划里写着Erlang，但据说从来没讲过）_

* 并行编程的策略

  * 分解

    * 任务分解

      不同的程序行为采用不同的执行单元实现。如GUI的前台和后台线程

    * 数据分解

      对不同的数据块执行相同的操作。如音频、图像和科学计算的应用

    * 数据流分解

      对数据处理阶段的不同操作进行分解。可以类比CPU中的流水线

* 并行编程的方法（设计模式）

  * 任务并行模式

    * 阶段并行

      将整个任务划分为多个阶段。每个阶段内部并行，并在下个任务前同步

  * 分治

  * 几何分解

  * 流水线

  * 设计模式与分解方式的对应

    | 设计模式     | 分解范式           |
    | :----------- | ------------------ |
    | 阶段并行     | 任务分解或数据分解 |
    | 分治模式     | 任务分解或数据分解 |
    | 几何分解模式 | 数据分解           |
    | 流水线模式   | 数据流分解         |



## Windows多核编程

* 进程

  * 一个地址空间+若干线程+系统资源
  * 操作系统资源分配的最小单位

* 线程

  * 执行单元
  * 操作系统任务调度的最小单位

* 

* ```c
  HANDLE CreateThread(
  	LPSECURITY_ATTRIBUTES lpThreadAtrributes,
  	DWORD dwStackSize,
  	LPTHREAD_START_ROUTINE lpStartAddress,
  	LPVOID lpParameter,
  	DWORD dwCreationFlags,
  	LPDWORD lpThreadId);
  ```

  ```c
  VOID ExitThread(DWORD dwExitCode);
  ```

  ```c
  DWORD WINAPI ThreadFunc(LPVOID data);
  ```

* `HANDLE GetCurrentProcess()`

  `HANDLE GetCurrentThread()`

  `DWORD GetCurrentProcessId();

  `DWORD GetCurrentThreadId();

* `DWORD SuspendThread(HANDLE hThread)`

  `DWORD ResumeThread(HANDLE hThread)`

  `BOOL TerminateThread(HANDLE hThread, DWORD dwExitCode)`

### 同步

* 互锁函数（其实就是原子操作和CAS）

  | 函数名                            | 参数和功能                                                   |
  | --------------------------------- | ------------------------------------------------------------ |
  | InterlockedIncrement              | 参数为PLONG类型。使一个LONG变量增1                           |
  | InterlockedDecrement              | 参数为PLONG类型。使一个LONG变量减1                           |
  | InterlockedExchangeAdd            | 参数1为PLONG类型，参数2为LONG类型。将参 数2加到参数1指向的变量中 |
  | InterlockedExchange               | 参数1为PLONG类型，参数2为LONG类型。将参 数2的值赋给参数1指向的值 ；返回原始值 |
  | InterlockedExchangePointer        | 参数为PVOID* 类型，参数2为PVOID类型。功能 同上。具体参见帮助 |
  | InterlockedCompareExchange        | 参数1为PLONG类型，参数2为LONG类型，参数3 为LONG类型。将参数1指向的值与参数3比较， 相同则把参数2的值赋给参数1指向的值。不相同则不变 |
  | InterlockedCompareExchangePointer | 参数1为PVOID* 类型，参数2为PVOID类型，参数 3为PVOID。功能同上。具体参见帮助 |

* 自旋锁

  用Interlocked实现自旋锁：

  ```c
  BOOL g_fResourceInUse = FALSE;
  // ......
  while (InterlockedExchange(&g_fResourceInUse, TRUE) == TRUE)
  {
      sleep(0);
  }
  ```

* 临界区

  * 运行在用户模式
  * _其实是管程_

  ```c
  void InitializeCriticalSection( LPCRITICAL_SECTION );
  void EnterCriticalSection( LPCRITICAL_SECTION );
  void LeaveCriticalSection( LPCRITICAL_SECTION );
  void DeleteCriticalSection( LPCRITICAL_SECTION );
  ```

  ```c++
  CRITICAL_SECTION csMyCriticalSection;
  void CriticalSectionExample (void)
  {
  	InitializeCriticalSection (&csMyCriticalSection); //初始化临界区变量
  	__try
  	{
  		EnterCriticalSection (&csMyCriticalSection); //开始保护机制
  		//此处编写代码
  	}
  	__finally //异常处理，无论是否异常都执行此段代码
  	{
  		LeaveCriticalSection (&csMyCriticalSection); //撤销保护机制
  	}
  }
  ```

* 使用内核对象进行同步

  * Process，Thread，Job，File，Event，Semaphore，Mutex，File change Notification，Waitable timer，Console input

  ```c
  DWORD WaitForSingleObject(
  	HANDLE hObject,
  	DWORD dwMilliseconds);
  
  DWORD WaitForMultipleObjects(
  	DWORD dwCount, CONST HANDLE* phObjects,
  	BOOL fWaitAll,
  	DWORD dwMilliseconds);
  ```

  ```c
  DWORD dw = WaitForSingleObject(hProcess,5000);
  
  switch (dw) {
  	case WAIT_OBJECT_0:
  		//The process terminated.
  		break;
  	case WAIT_TIMEOUT:
  		//The process did not terminated within 5000 milliseconds.
  		break;
  	case WAIT_FAILED:
  		//bad call to function (invalid handle?)
  		break;
  }
  ```

  ```c
  HANDLE h[3];
  h[0] = hProcess1; h[1] = hProcess2; h[3] = hProcess3;
  DWORD dw = WaitForMultipleObject(3, h, FALSE, 5000);
  switch (dw) {
  	case WAIT_TIMEOUT:
  		//The process did not terminated within 5000 milliseconds.
  		break;
  	case WAIT_FAILED:
  		//bad call to function (invalid handle?)
  		break;
  	case WAIT_OBJECT_0 + 0:
  		//The process identified by h[0] (hProcess1) terminated.
  		break;
  	case WAIT_OBJECT_0 +1:
  		//The process identified by h[1] (hProcess2) terminated.
  		break;
  	case WAIT_OBJECT_0 + 2:
  		//The process identified by h[2] (hProcess3) terminated.
  		break;
  }
  ```

* 事件

  ```c
  HANDLE CreateEvent(
  	PSECURITY_ATTRIBUTES psa;
  	BOOL fManualReset,
  	BOOL fInitialState,
  	PCTSTR pszName);
  BOOL SetEvent(HANDLE hEvent);
  BOOL ResetEvent(HANDLE hEvent);
  ```

* 信号量

  ```c
  HANDLE CreateSemaphore(
  	LPSECURITY_ATTRIBUTES lpSemaphoreAttributes,
  	LONG lInitialCount,
  	LONG lMaximumCount,
  	LPCTSTR lpName);
  // 等待就用WaitForSingleObject
  BOOL ReleaseSemaphore(
  	HANDLE hSemaphore,
  	LONG lReleaseCount,
  	LPLONG lpPreviousCount);
  ```

* 互斥量

  ```c
  HANDLE CreateMutex(
  	LPSECURITY_ATTRIBUTES lpMutexAttributes,
  	BOOL bInitialOwner,
  	LPCTSTR lpName);
  // 等待就用WaitForSingleObject
  BOOL ReleaseMutex(HANDLE hMutex);
  ```

* 线程池

  ```c
  BOOL QueueUserWorkItem(
  	LPTHREAD_START_ROUTINE Function,
  	PVOID Context,
  	ULONG Flags);
  ```

* 线程优先级

  ```c
  Bool SetThreadPriority (HANDLE hPriority, int nPriority);
  ```

* 处理器亲和

   ```c
    DWORD_PTR SetThreadAffinityMask(
  	HANDLE threadHandle,
  	DWORD_PTR threadAffinityMask);
    BOOL GetProcessAffinityMask(
    HANDLE     hProcess,
    PDWORD_PTR lpProcessAffinityMask,
    PDWORD_PTR lpSystemAffinityMask
    );
    BOOL SetProcessAffinityMask(
    HANDLE    hProcess,
    DWORD_PTR dwProcessAffinityMask
    );  
   ```

* TLS

   ```c
    DWORD TlsAlloc(void);
    BOOL TlsSetValue(
  	DWORD dwTlsIndex,
      LPVOID lpTlsValue
    );
    LPVOID TlsGetValue(DWORD dwTlsIndex);
    BOOL TlsFree(DWORD dwTlsIndex);
   ```

## Linux多核编程

* exec系列函数

  ```c
  int execl(const char *path, const char *arg0, ..., (char *)0);
  int execlp(const char *file, const char *arg0, ..., (char *)0);
  int execle(const char *path, const char *arg0, ..., (char *)0, char *const envp[]);
  int execv(const char *path, char *const argv[]);
  int execvp(const char *file, char *const argv[]);
  int execve(const char *path, char *const argv[], char *const envp[]); 
  ```

*  fork

  ```c
  pid_t fork(void);
  ```

  ```c
  if(fork() == 0)
  	{子进程执行的代码段；}
  else
  	{父进程执行的代码段；}
  ```

*  

  ```c
  void exit(int status);
  ```

*   

  ```c
  int atexit(void (*function)(void));
  ```

*  

  ```c
  pid_t wait(int *status);
  pid_t waitpid(pid_t pid, int *status, int options);
  ```

  用法自行查文档

*  信号机制

  自己看

*  pthread

  太多了，都是API……整理没啥意义，自己看课件

## OpenMP

自己看课件……太多了


